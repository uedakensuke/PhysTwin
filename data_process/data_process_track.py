# FIlter the tracking based on the object and controller mask, filter the track based on the neighbour motion
# Get the nearest controller points that are valid across all frames
import os
import pickle
from argparse import ArgumentParser

import numpy as np
import open3d as o3d
from tqdm import tqdm
import matplotlib.pyplot as plt

from .utils.path import PathResolver


def exist_dir(dir):
    if not os.path.exists(dir):
        os.makedirs(dir)


def getSphereMesh(center, radius=0.1, color=[0, 0, 0]):
    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=radius).translate(center)
    sphere.paint_uniform_color(color)
    return sphere


def filter_motion(track_data, neighbor_dist=0.01, *, show_window=False):
    # Calculate the motion of each point
    object_points = track_data["object_points"]
    object_colors = track_data["object_colors"]
    object_visibilities = track_data["object_visibilities"]
    object_motions = np.zeros_like(object_points)
    object_motions[:-1] = object_points[1:] - object_points[:-1]
    object_motions_valid = np.zeros_like(object_visibilities)
    object_motions_valid[:-1] = np.logical_and(
        object_visibilities[:-1], object_visibilities[1:]
    )

    y_min, y_max = np.min(object_points[0, :, 1]), np.max(object_points[0, :, 1])
    y_normalized = (object_points[0, :, 1] - y_min) / (y_max - y_min)
    rainbow_colors = plt.cm.rainbow(y_normalized)[:, :3]

    num_frames = object_points.shape[0]
    num_points = object_points.shape[1]

    if show_window:
        vis = o3d.visualization.Visualizer()
        vis.create_window()

    for i in tqdm(range(num_frames - 1)):
        # Convert the points of the current frame to an Open3D point cloud
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(object_points[i])
        pcd.colors = o3d.utility.Vector3dVector(object_colors[i])
        # Build the KDTree
        kdtree = o3d.geometry.KDTreeFlann(pcd)
        # modified_points = []
        # new_points = []
        # Get the neighbors for each points and filter motion based on the motion difference between neighbours and the point
        for j in range(num_points):
            if object_motions_valid[i, j] == 0:
                continue
            # Get the neighbors within neighbor_dist
            [k, idx, _] = kdtree.search_radius_vector_3d(
                object_points[i, j], neighbor_dist
            )
            neighbors = [index for index in idx if object_motions_valid[i, index] == 1]
            if len(neighbors) < 5:
                object_motions_valid[i, j] = 0
                # modified_points.append(object_points[i, j])
                # new_points.append(object_points[i + 1, j])
            motion_diff = np.linalg.norm(
                object_motions[i, j] - object_motions[i, neighbors], axis=1
            )
            if (motion_diff < neighbor_dist / 2).sum() < 0.5 * len(neighbors):
                object_motions_valid[i, j] = 0
                # modified_points.append(object_points[i, j])
                # new_points.append(object_points[i + 1, j])

        motion_pcd = o3d.geometry.PointCloud()
        motion_pcd.points = o3d.utility.Vector3dVector(
            object_points[i][np.where(object_motions_valid[i])]
        )
        motion_pcd.colors = o3d.utility.Vector3dVector(
            object_colors[i][np.where(object_motions_valid[i])]
        )
        motion_pcd.colors = o3d.utility.Vector3dVector(
            rainbow_colors[np.where(object_motions_valid[i])]
        )

        if show_window:
            if i == 0:
                render_motion_pcd = motion_pcd
                vis.add_geometry(render_motion_pcd)
                # Adjust the viewpoint
                view_control = vis.get_view_control()
                view_control.set_front([1, 0, -2])
                view_control.set_up([0, 0, -1])
                view_control.set_zoom(1)
            else:
                render_motion_pcd.points = o3d.utility.Vector3dVector(motion_pcd.points)
                render_motion_pcd.colors = o3d.utility.Vector3dVector(motion_pcd.colors)
                vis.update_geometry(render_motion_pcd)
                vis.poll_events()
                vis.update_renderer()
        # modified_num = len(modified_points)
        # print(f"Object Frame {i}: {modified_num} points are modified")

    if show_window:
        vis.destroy_window()

    track_data["object_motions_valid"] = object_motions_valid

    controller_points = track_data["controller_points"]
    controller_colors = track_data["controller_colors"]
    controller_visibilities = track_data["controller_visibilities"]
    controller_motions = np.zeros_like(controller_points)
    controller_motions[:-1] = controller_points[1:] - controller_points[:-1]
    controller_motions_valid = np.zeros_like(controller_visibilities)
    controller_motions_valid[:-1] = np.logical_and(
        controller_visibilities[:-1], controller_visibilities[1:]
    )
    num_points = controller_points.shape[1]
    # Filter all points that disappear in the sequence
    mask = np.prod(controller_visibilities, axis=0)

    y_min, y_max = np.min(controller_points[0, :, 1]), np.max(
        controller_points[0, :, 1]
    )
    y_normalized = (controller_points[0, :, 1] - y_min) / (y_max - y_min)
    rainbow_colors = plt.cm.rainbow(y_normalized)[:, :3]

    if show_window:
        vis = o3d.visualization.Visualizer()
        vis.create_window()

    for i in tqdm(range(num_frames - 1)):
        # Convert the points of the current frame to an Open3D point cloud
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(controller_points[i])
        pcd.colors = o3d.utility.Vector3dVector(controller_colors[i])
        # Build the KDTree
        kdtree = o3d.geometry.KDTreeFlann(pcd)
        # Get the neighbors for each points and filter motion based on the motion difference between neighbours and the point
        for j in range(num_points):
            if mask[j] == 0:
                controller_motions_valid[i, j] = 0
            if controller_motions_valid[i, j] == 0:
                continue
            # Get the neighbors within neighbor_dist
            [k, idx, _] = kdtree.search_radius_vector_3d(
                controller_points[i, j], neighbor_dist
            )
            neighbors = [
                index for index in idx if controller_motions_valid[i, index] == 1
            ]
            if len(neighbors) < 5:
                controller_motions_valid[i, j] = 0
                mask[j] = 0

            motion_diff = np.linalg.norm(
                controller_motions[i, j] - controller_motions[i, neighbors], axis=1
            )
            if (motion_diff < neighbor_dist / 2).sum() < 0.5 * len(neighbors):
                controller_motions_valid[i, j] = 0
                mask[j] = 0

        motion_pcd = o3d.geometry.PointCloud()
        motion_pcd.points = o3d.utility.Vector3dVector(
            controller_points[i][np.where(mask)]
        )
        motion_pcd.colors = o3d.utility.Vector3dVector(
            controller_colors[i][np.where(controller_motions_valid[i])]
        )

        if show_window:
            if i == 0:
                render_motion_pcd = motion_pcd
                vis.add_geometry(render_motion_pcd)
                # Adjust the viewpoint
                view_control = vis.get_view_control()
                view_control.set_front([1, 0, -2])
                view_control.set_up([0, 0, -1])
                view_control.set_zoom(1)
            else:
                render_motion_pcd.points = o3d.utility.Vector3dVector(motion_pcd.points)
                render_motion_pcd.colors = o3d.utility.Vector3dVector(motion_pcd.colors)
                vis.update_geometry(render_motion_pcd)
                vis.poll_events()
                vis.update_renderer()

    track_data["controller_mask"] = mask
    return track_data


def get_final_track_data(track_data):
    controller_points = track_data["controller_points"]
    mask = track_data["controller_mask"]

    new_controller_points = controller_points[:, np.where(mask)[0], :]
    assert len(new_controller_points[0]) >= 30
    # Do farthest point sampling on the valid controller points to select the final controller points
    valid_indices = np.arange(len(new_controller_points[0]))
    points_map = {}
    sample_points = []
    for i in valid_indices:
        points_map[tuple(new_controller_points[0, i])] = i
        sample_points.append(new_controller_points[0, i])
    sample_points = np.array(sample_points)
    sample_pcd = o3d.geometry.PointCloud()
    sample_pcd.points = o3d.utility.Vector3dVector(sample_points)
    fps_pcd = sample_pcd.farthest_point_down_sample(30)
    final_indices = []
    for point in fps_pcd.points:
        final_indices.append(points_map[tuple(point)])

    print(f"Controller Point Number: {len(final_indices)}")

    # Get the nearest controller points and their colors
    nearest_controller_points = new_controller_points[:, final_indices]

    # object_pcd = o3d.geometry.PointCloud()
    # object_pcd.points = o3d.utility.Vector3dVector(valid_object_points)
    # object_pcd.colors = o3d.utility.Vector3dVector(
    #     object_colors[0][np.where(object_motions_valid[0])]
    # )
    # controller_meshes = []
    # for j in range(nearest_controller_points.shape[1]):
    #     origin = nearest_controller_points[0, j]
    #     origin_color = [1, 0, 0]
    #     controller_meshes.append(
    #         getSphereMesh(origin, color=origin_color, radius=0.005)
    #     )
    # o3d.visualization.draw_geometries([object_pcd])
    # o3d.visualization.draw_geometries([object_pcd] + controller_meshes)

    track_data.pop("controller_points")
    track_data.pop("controller_colors")
    track_data.pop("controller_visibilities")
    track_data["controller_points"] = nearest_controller_points

    return track_data


def visualize_track(track_data):
    object_points = track_data["object_points"]
    object_motions_valid = track_data["object_motions_valid"]
    controller_points = track_data["controller_points"]

    frame_num = object_points.shape[0]

    vis = o3d.visualization.Visualizer()
    vis.create_window()
    controller_meshes = []
    prev_center = []

    y_min, y_max = np.min(object_points[0, :, 1]), np.max(object_points[0, :, 1])
    y_normalized = (object_points[0, :, 1] - y_min) / (y_max - y_min)
    rainbow_colors = plt.cm.rainbow(y_normalized)[:, :3]

    for i in range(frame_num):
        object_pcd = o3d.geometry.PointCloud()
        object_pcd.points = o3d.utility.Vector3dVector(
            object_points[i, np.where(object_motions_valid[i])[0], :]
        )
        # object_pcd.colors = o3d.utility.Vector3dVector(
        #     object_colors[i, np.where(object_motions_valid[i])[0], :]
        # )
        object_pcd.colors = o3d.utility.Vector3dVector(
            rainbow_colors[np.where(object_motions_valid[i])[0]]
        )

        if i == 0:
            render_object_pcd = object_pcd
            vis.add_geometry(render_object_pcd)
            # Use sphere mesh for each controller point
            for j in range(controller_points.shape[1]):
                origin = controller_points[i, j]
                origin_color = [1, 0, 0]
                controller_meshes.append(
                    getSphereMesh(origin, color=origin_color, radius=0.01)
                )
                vis.add_geometry(controller_meshes[-1])
                prev_center.append(origin)
            # Adjust the viewpoint
            view_control = vis.get_view_control()
            view_control.set_front([1, 0, -2])
            view_control.set_up([0, 0, -1])
            view_control.set_zoom(1)
        else:
            render_object_pcd.points = o3d.utility.Vector3dVector(object_pcd.points)
            render_object_pcd.colors = o3d.utility.Vector3dVector(object_pcd.colors)
            vis.update_geometry(render_object_pcd)
            for j in range(controller_points.shape[1]):
                origin = controller_points[i, j]
                controller_meshes[j].translate(origin - prev_center[j])
                vis.update_geometry(controller_meshes[j])
                prev_center[j] = origin
            vis.poll_events()
            vis.update_renderer()

class PcdTrackProcessor:

    def __init__(self, raw_path:str, base_path:str, case_name:str, *, show_window=False):
        self.path = PathResolver(raw_path,base_path,case_name)
        self.show_window = show_window

    def process(self): 
        # Filter the track data using the semantic mask of object and controller
        filtered_track_data =self._filter_track()
        # Filter motion
        filtered_motion_track_data = filter_motion(filtered_track_data,show_window=self.show_window)

        final_track_data = get_final_track_data(filtered_motion_track_data)

        with open(self.path.tarck_process_data_pkl, "wb") as f:
            pickle.dump(final_track_data, f)

        if self.show_window:
            visualize_track(final_track_data)

    # Based on the valid mask, filter out the bad tracking data
    def _filter_track(self):
        frame_num = self.path.find_num_frame()

        with open(self.path.processed_masks_pkl, "rb") as f:
            processed_masks = pickle.load(f)

        # Filter out the points not valid in the first frame
        object_points = []
        object_colors = []
        object_visibilities = []
        controller_points = []
        controller_colors = []
        controller_visibilities = []
        for i in range(self.path.find_num_cam()):
            current_track_data = np.load(self.path.get_tracking_data_path(i))
            # Filter out the track data
            tracks = current_track_data["tracks"]
            tracks = np.round(tracks).astype(int)
            visibility = current_track_data["visibility"]
            assert tracks.shape[0] == frame_num
            num_points = np.shape(tracks)[1]

            # Locate the track points in the object mask of the first frame
            object_mask = processed_masks[0][i]["object"]
            track_object_idx = np.zeros((num_points), dtype=int)
            for j in range(num_points):
                if visibility[0, j] == 1:
                    track_object_idx[j] = object_mask[tracks[0, j, 0], tracks[0, j, 1]]
            # Locate the controller points in the controller mask of the first frame
            controller_mask = processed_masks[0][i]["controller"]
            track_controller_idx = np.zeros((num_points), dtype=int)
            for j in range(num_points):
                if visibility[0, j] == 1:
                    track_controller_idx[j] = controller_mask[
                        tracks[0, j, 0], tracks[0, j, 1]
                    ]

            # Filter out bad tracking in other frames
            for frame_idx in range(1, frame_num):
                # Filter based on object_mask
                object_mask = processed_masks[frame_idx][i]["object"]
                for j in range(num_points):
                    try:
                        if track_object_idx[j] == 1 and visibility[frame_idx, j] == 1:
                            if not object_mask[
                                tracks[frame_idx, j, 0], tracks[frame_idx, j, 1]
                            ]:
                                visibility[frame_idx, j] = 0
                    except:
                        # Sometimes the track coordinate is out of image
                        visibility[frame_idx, j] = 0
                # Filter based on controller_mask
                controller_mask = processed_masks[frame_idx][i]["controller"]
                for j in range(num_points):
                    if track_controller_idx[j] == 1 and visibility[frame_idx, j] == 1:
                        if not controller_mask[
                            tracks[frame_idx, j, 0], tracks[frame_idx, j, 1]
                        ]:
                            visibility[frame_idx, j] = 0

            # Get the track point cloud
            track_points = np.zeros((frame_num, num_points, 3))
            track_colors = np.zeros((frame_num, num_points, 3))
            for frame_idx in range(frame_num):
                data = np.load(self.path.get_pcd_data_path(frame_idx))
                points = data["points"]
                colors = data["colors"]

                track_points[frame_idx][np.where(visibility[frame_idx])] = points[i][
                    tracks[frame_idx, np.where(visibility[frame_idx])[0], 0],
                    tracks[frame_idx, np.where(visibility[frame_idx])[0], 1],
                ]
                track_colors[frame_idx][np.where(visibility[frame_idx])] = colors[i][
                    tracks[frame_idx, np.where(visibility[frame_idx])[0], 0],
                    tracks[frame_idx, np.where(visibility[frame_idx])[0], 1],
                ]

            object_points.append(track_points[:, np.where(track_object_idx)[0], :])
            object_colors.append(track_colors[:, np.where(track_object_idx)[0], :])
            object_visibilities.append(visibility[:, np.where(track_object_idx)[0]])
            controller_points.append(track_points[:, np.where(track_controller_idx)[0], :])
            controller_colors.append(track_colors[:, np.where(track_controller_idx)[0], :])
            controller_visibilities.append(visibility[:, np.where(track_controller_idx)[0]])

        object_points = np.concatenate(object_points, axis=1)
        object_colors = np.concatenate(object_colors, axis=1)
        object_visibilities = np.concatenate(object_visibilities, axis=1)
        controller_points = np.concatenate(controller_points, axis=1)
        controller_colors = np.concatenate(controller_colors, axis=1)
        controller_visibilities = np.concatenate(controller_visibilities, axis=1)

        track_data = {}
        track_data["object_points"] = object_points
        track_data["object_colors"] = object_colors
        track_data["object_visibilities"] = object_visibilities
        track_data["controller_points"] = controller_points
        track_data["controller_colors"] = controller_colors
        track_data["controller_visibilities"] = controller_visibilities

        return track_data


if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("--raw_path", type=str, required=True)
    parser.add_argument("--base_path", type=str, required=True)
    parser.add_argument("--case_name", type=str, required=True)
    parser.add_argument("--show_window", action='store_true' )
    args = parser.parse_args()

    ptp = PcdTrackProcessor(args.raw_path, args.base_path, args.case_name, show_window=args.show_window)
    ptp.process()
